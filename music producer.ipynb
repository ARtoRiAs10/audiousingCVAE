{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0N0ziwIUdHCU9wuMA1TwN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARtoRiAs10/audiousingCVAE/blob/ARtoRiAs10-patch-1/music%20producer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEepSu1I8Y8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e8f5c8-1938-4d4e-96c5-3ea82bc4aa25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SlUIf5wD8nx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "\n",
        "import os\n",
        "\n",
        "import csv\n"
      ],
      "metadata": {
        "id": "JECTNm9h8pFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_probability as tpa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "\n"
      ],
      "metadata": {
        "id": "UGBc47zGOoRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons==0.19.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N1gSAHDhTCh",
        "outputId": "356b2b2d-fd24-4e42-db72-7de8c650e355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.19.0\n",
            "  Downloading tensorflow_addons-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.19.0) (23.1)\n",
            "Collecting typeguard>=2.7 (from tensorflow-addons==0.19.0)\n",
            "  Downloading typeguard-4.1.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.19.0) (4.7.1)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0 typeguard-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4-Ntc3khody",
        "outputId": "76cf1675-8b22-4854-dbc8-f59dac7db3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import imageio\n",
        "import time\n",
        "import IPython.display as ipd\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "eCI-eHpPPWy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YeWuW9ezLMNR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T7jsdn_ZOnaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtccLwAjLNqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ymyd9XpOZwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import session\n",
        "seed=123\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "metadata": {
        "id": "hltojl9bOaJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 60000\n",
        "BATCH_SIZE= 10\n",
        "test_size=10000\n",
        "epochs=20\n",
        "\n",
        "latent_dim=2\n",
        "num_examples_to_generate = 10\n",
        "\n",
        "BASE_PATH = '.../content/archive (1).zip/genres'"
      ],
      "metadata": {
        "id": "DyCCR51hRVp-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sEjoG2B7Y23c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQSqtsAtR0oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing\n"
      ],
      "metadata": {
        "id": "6Y_ZRWqMR7i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def DatasetLoader(class_):\n",
        "  music_list = np.array(sorted(os.listdir(BASE_PATH+'/'+class_)))\n",
        "  train_music_1= list(music_list[[0,52,19,39,71,12,75,85,3,45,24,46,88]])\n",
        "\n",
        "  train_music_2= list(music_list[[4,43,56,55,45,31,11,13,70,3,7,21,78]])\n",
        "\n",
        "  TrackSet_1 = [(BASE_PATH)+'/'+class_+'/%$'%(x) for x in train_music_1]\n",
        "\n",
        "  TrackSet_2 = [(BASE_PATH)+'/'+class_+'/%$'%(x) for x in train_music_2]\n",
        "\n",
        "\n",
        "  return TrackSet_1, TrackSet_2"
      ],
      "metadata": {
        "id": "nyKjGrBfSDmS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(file_):\n",
        "  data_, sampling_rate= librosa.load(file_,sr=3000, offset=0.0, duration=30)\n",
        "\n",
        "  data_ = data_.reshape(1,90001)\n",
        "  return data_\n",
        "\n",
        "map_data = lambda filename: tf.compat.v1.py_func(load, [filename], [tf.float32])\n"
      ],
      "metadata": {
        "id": "wlrdOReQUWSe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "TrackSet_1, TrackSet_2 = DatasetLoader('jazz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "SLZWG_4NVq06",
        "outputId": "7f1bbe21-64f1-4b2d-8104-41b7f21e5433"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-9e92e366e3f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrackSet_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrackSet_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jazz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-45-08480e020114>\u001b[0m in \u001b[0;36mDatasetLoader\u001b[0;34m(class_)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mDatasetLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmusic_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_music_1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m52\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m39\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m71\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m85\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtrain_music_2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m78\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.../content/archive (1).zip/genres/jazz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ew9uC8HuVrDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample original **music**"
      ],
      "metadata": {
        "id": "drq5SVyyWKlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = TrackSet_1[1]\n",
        "\n",
        "sample_, sampling_rate= librosa.load(sample, sr=3000, offset=0.0, duration=30)\n",
        "\n",
        "ipd.audio (sample_,rate=3000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "SHWOQ3w9WPZ5",
        "outputId": "5bb58826-e270-44c7-f8ae-8157840b0e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-cb13d3acdabb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrackSet_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TrackSet_1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "plt.figure(figsize=(18,15))\n",
        "\n",
        "for i in range(4):\n",
        "  plt.subplot(4,4,i+1)\n",
        "  j = load(TrackSet_1[i])\n",
        "  librosa.display.AdaptiveWaveplot(j[0], sr=3000)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "Ui12PBGYXeTk",
        "outputId": "81f6a5db-72a8-4895-9e82-37d1b5d04a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b47e100d37bd>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrackSet_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdaptiveWaveplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TrackSet_1' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset =(\n",
        "    tf.data.Dataset.from_tensor_slices((TrackSet_1)).map(map_data, num_parallel_calls=AUTOTUNE).shuffle(3).batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "test_dataset=(\n",
        "    tf.data.Dataset.from_tensor_slices((TrackSet_2))\n",
        "    .map(map_data, num_parallel_calls=AUTOTUNE)\n",
        "    .shuffle(3)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "Fa7IvPHzYRwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_LxcA5UXejg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V4G-718kXeyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network architecture\n"
      ],
      "metadata": {
        "id": "jOG96ezZaBK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet1DBlock(tf.keras.Model):\n",
        "    def __init__(self, kernel_size, filters, type = 'encode', prefix = ''):\n",
        "        super(Resnet1DBlock, self).__init__()\n",
        "\n",
        "        if type == 'encode':\n",
        "            self.conv1a = layers.Conv1D(filters, kernel_size, 2, padding = \"same\", \\\n",
        "                                        name = prefix + 'conv1a')\n",
        "            self.conv1b = layers.Conv1D(filters, kernel_size, 1, padding = \"same\", \\\n",
        "                                        name = prefix + 'conv1b')\n",
        "            self.norm1a = tfa.layers.InstanceNormalization(name =  prefix + 'norm1a')\n",
        "            self.norm1b = tfa.layers.InstanceNormalization(name =  prefix + 'norm1b')\n",
        "        elif type == 'decode':\n",
        "            self.conv1a = layers.Conv1DTranspose(filters, kernel_size, 1, padding = \"same\", \\\n",
        "                                                name =  prefix + 'conv1a')\n",
        "            self.conv1b = layers.Conv1DTranspose(filters, kernel_size, 1, padding = \"same\", \\\n",
        "                                                name =  prefix + 'conv1b')\n",
        "            self.norm1a = tf.keras.layers.BatchNormalization(name =  prefix + 'norm1a')\n",
        "            self.norm1b = tf.keras.layers.BatchNormalization(name =  prefix + 'norm1b')\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        x = tf.nn.relu(input_tensor)\n",
        "        x = self.conv1a(x)\n",
        "        x = self.norm1a(x)\n",
        "        x = layers.LeakyReLU(0.4)(x)\n",
        "\n",
        "        x = self.conv1b(x)\n",
        "        x = self.norm1b(x)\n",
        "        x = layers.LeakyReLU(0.4)(x)\n",
        "\n",
        "        x += input_tensor\n",
        "        return tf.nn.relu(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "NjC93o2kaJ5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, latent_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape = (1, 90001), name = 'input_encoder'),\n",
        "\n",
        "                layers.Conv1D(64, 1, 2, name = 'conv1_layer1'),\n",
        "                Resnet1DBlock(64, 1, 'encode', prefix = 'res1_'),\n",
        "                layers.Conv1D(128, 1, 2, name = 'conv1_layer2'),\n",
        "                Resnet1DBlock(128, 1, 'encode', prefix = 'res2_'),\n",
        "                layers.Conv1D(128, 1, 2, name = 'conv1_layer3'),\n",
        "                Resnet1DBlock(128, 1, 'encode', prefix = 'res3_'),\n",
        "                layers.Conv1D(256, 1, 2, name = 'conv1_layer4'),\n",
        "                Resnet1DBlock(256, 1, 'encode', prefix = 'res4_'),\n",
        "\n",
        "                layers.Flatten(name = 'flatten'),\n",
        "                layers.Dense(latent_dim + latent_dim, name = 'dense'),\n",
        "            ]\n",
        "        )\n",
        "        self.decoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape = (latent_dim,), name = 'input_decoder'),\n",
        "                layers.Reshape(target_shape = (1, latent_dim)),\n",
        "                Resnet1DBlock(512, 1, 'decode', prefix = 'res1_'),\n",
        "                layers.Conv1DTranspose(512, 1, 1, name = 'Conv1Trans_Layer1'),\n",
        "                Resnet1DBlock(256, 1, 'decode', prefix = 'res2_'),\n",
        "                layers.Conv1DTranspose(256, 1, 1, name = 'Conv1Trans_Layer2'),\n",
        "                Resnet1DBlock(128, 1, 'decode', prefix = 'res3_'),\n",
        "                layers.Conv1DTranspose(128, 1, 1, name = 'Conv1Trans_Layer3'),\n",
        "                Resnet1DBlock(64, 1, 'decode', prefix = 'res4_'),\n",
        "                layers.Conv1DTranspose(64, 1, 1, name = 'Conv1Trans_Layer4'),\n",
        "                layers.Conv1DTranspose(90001, 1, 1, name = 'Conv1Trans_Layer5')\n",
        "            ]\n",
        "        )\n",
        "@tf.function\n",
        "def sample(self, esp=None):\n",
        "      if eps is None:\n",
        "        eps = tf.random.normal(shape=(200, self.latent_dim))\n",
        "      return self.decode(eps, apply_sigmoid=True)\n",
        "@tf.function\n",
        "def encode(self,x):\n",
        "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "    return mean, logvar\n",
        "\n",
        "@tf.function\n",
        "def reparameterize(self, mean, logvar):\n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    return eps* tf.exp(logvar* .5)+ mean\n",
        "@tf.function\n",
        "def decode(self, z, apply_sigmoid=False):\n",
        "    logits = self.decoder(z)\n",
        "    if apply_sigmoid:\n",
        "      probs= tf.sigmoid(logits)\n",
        "      return probs\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "220R7UtedmmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.0003,beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
      ],
      "metadata": {
        "id": "UhFZ-gwdCdTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.math.log(2.* np.pi)\n",
        "  return tf.reduce_sum(\n",
        "      -.5* ((sample - mean)**2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "      axis = raxis\n",
        "  )"
      ],
      "metadata": {
        "id": "FOR5mx7CCyS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_loss(model,x):\n",
        "  mean, logvar = model.encode(x)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  x_logit = model.decode(z)\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
      ],
      "metadata": {
        "id": "_MOCI6EoCy2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOSS OPTIMIZATION"
      ],
      "metadata": {
        "id": "4HisIZWEGiQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import gradients\n",
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "   \"\"\"Executes one training step and returns the loss.\n",
        "\n",
        "       This function computes the loss and gradients, and uses the latter to\n",
        "       update the model's parameters.\n",
        "     \"\"\"\n",
        "   with tf.GradientTape() as tape:\n",
        "      mean, logvar = model.encode(x)\n",
        "      z = model.reparameterize(mean, logvar)\n",
        "      x_logit = model.decode(z)\n",
        "      cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "      logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2])\n",
        "      logpz = log_normal_pdf(z, 0., 0.)\n",
        "      logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "\n",
        "      loss_KL = -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "      reconstruction_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(x, x_logit))\n",
        "\n",
        "      total_loss = reconstruction_loss + loss_KL\n",
        "      gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KprE8s2PGl6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_vector_for_generation = tf.random.normal(\n",
        "    shape=[num_examples_to_generate, latent_dim]\n",
        ")\n",
        "\n",
        "model = CVAE(latent_dim)"
      ],
      "metadata": {
        "id": "y0zhvICKfsas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_sample, save):\n",
        "    mean, logvar = model.encode(test_sample)\n",
        "    z = model.reparameterize(mean, logvar)\n",
        "    predictions = model.sample(z)\n",
        "    fig = plt.figure(figsize=(18, 15))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        wave = np.asarray(predictions[i])\n",
        "        librosa.display.waveplot(wave[0], sr=3000)\n",
        "\n",
        "    # tight_layout minimizes the overlap between 2 sub-plots\n",
        "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
        "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
        "    plt.show()\n",
        "# Pick a sample of the test set for g"
      ],
      "metadata": {
        "id": "rduEXEjxxaoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert BATCH_SIZE >= num_examples_to_generate\n",
        "for test_batch in test_dataset.take(1):\n",
        "    test_sample = test_batch[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "8fl1pNSHyODR",
        "outputId": "e0e3a02a-3ae7-413c-86ca-0ebbb88f114a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4ad0a296d76f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnum_examples_to_generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtest_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6h54oQZ71Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model\n"
      ],
      "metadata": {
        "id": "X3HjHIEEPOmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_save_images(model, 0, test_sample, 'jazz')\n",
        "def train(train_dataset, test_dataset, model, save):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        start_time = time.time()\n",
        "        for train_x in train_dataset:\n",
        "            train_x = np.asarray(train_x)[0]\n",
        "            train_step(model, train_x, optimizer)\n",
        "        end_time = time.time()\n",
        "\n",
        "        loss = tf.keras.metrics.Mean()\n",
        "        for test_x in test_dataset:\n",
        "            test_x = np.asarray(test_x)[0]\n",
        "            loss(compute_loss(model, test_x))\n",
        "        display.clear_output(wait=False)\n",
        "        elbo = -loss.result()\n",
        "        print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'.format(epoch,\n",
        "                                                                                       elbo,\n",
        "                                                                                       end_time - start_time\n",
        "                                                                                      ))\n",
        "        generate_and_save_images(model,\n",
        "                                 epoch,\n",
        "                                 test_sample,\n",
        "                                 save)\n",
        "train(train_dataset, test_dataset, model, 'jazz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "BicsThDsPUSC",
        "outputId": "70a6a8b4-396f-43a9-ac5e-707ea74d5e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-7db41d03e8f0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_and_save_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jazz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_sample' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q imageio"
      ],
      "metadata": {
        "id": "J2VBVMF9Qr6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio"
      ],
      "metadata": {
        "id": "RSxB-FxcQ1kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anim_file_1 = 'jazz_cvae.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file_1, mode='I') as writer:\n",
        "    filenames = glob.glob('jazz*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "rlR1XAdSQ5Yl",
        "outputId": "187f01ae-9534-42f6-a5da-83a997706502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-e5620324aa87>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rk89FKERRFWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#visualization"
      ],
      "metadata": {
        "id": "bNIzChy_R3Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file_1)"
      ],
      "metadata": {
        "id": "HFTVnrN_R7K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generated music"
      ],
      "metadata": {
        "id": "UB4QPPnfSAvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(test_dataset, model):\n",
        "    save_music = []\n",
        "    for test in test_dataset:\n",
        "        mean, logvar = model.encode(test)\n",
        "        z = model.reparameterize(mean, logvar)\n",
        "        predictions = model.sample(z)\n",
        "        for pred in predictions:\n",
        "            wave = np.asarray(pred)\n",
        "            save_music.append(wave)\n",
        "    return save_music\n",
        "\n",
        "saved_musics = inference(test_dataset, model)"
      ],
      "metadata": {
        "id": "Ff6nBmaISHYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music1=saved_musics[0][0]\n",
        "ipd.Audio(music1,rate=3000)"
      ],
      "metadata": {
        "id": "qEedsU8kSMFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}